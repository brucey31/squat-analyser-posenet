{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olive-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Bruce Pannaman\"\n",
    "# Taken from https://github.com/rwightman/posenet-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "associate-rhythm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import statistics\n",
    "import math\n",
    "import posenet\n",
    "import time\n",
    "import IPython\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-worth",
   "metadata": {},
   "source": [
    "## Load Posenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     model_cfg, model_outputs = posenet.load_model(101, sess)\n",
    "#     output_stride = model_cfg['output_stride']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-celebration",
   "metadata": {},
   "source": [
    "## Setup Webcam Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cam):\n",
    "    \"\"\"\n",
    "    Grab the latest frame from the cv2.VideoCapture instances that is connected to my Mac's Webcam\n",
    "    \n",
    "    Returns a full size frame for viewing and another one that is 25% of the size for faster facial recognition scans per frame\n",
    "\n",
    "    \"\"\"\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # flip image for natural viewing\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    return frame, small_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_image(a, fmt='jpeg'):\n",
    "    \"\"\"\n",
    "    Creates an image from the numpy array that you have been edited. Only use when you want to view it again.\n",
    "    \n",
    "    #Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "    \"\"\"\n",
    "    #Create binary stream object\n",
    "    f = BytesIO()\n",
    "\n",
    "    #Convert array to binary stream object\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "\n",
    "    return IPython.display.Image(data=f.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    width, height, inference_time, results = yolo.inference(frame)\n",
    "    for detection in results:\n",
    "#         print(detection)\n",
    "        id, name, confidence, x, y, w, h = detection\n",
    "        color = colors[id]\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.rectangle(frame, (x, y+h - 35), (x+w, y+h), color, cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, classes[id], (x + 6, y+h - 6), font, 1.0, (255, 255, 255), 1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame2(cap, pa_status, calibrated, squat_count):        \n",
    "        input_image, display_image, output_scale = posenet.read_cap(cap, scale_factor=0.4, output_stride=output_stride)\n",
    "\n",
    "\n",
    "        heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = sess.run(\n",
    "            model_outputs, feed_dict={'image:0': input_image})\n",
    "\n",
    "        pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multi.decode_multiple_poses(\n",
    "            heatmaps_result.squeeze(axis=0),\n",
    "            offsets_result.squeeze(axis=0),\n",
    "            displacement_fwd_result.squeeze(axis=0),\n",
    "            displacement_bwd_result.squeeze(axis=0),\n",
    "            output_stride=output_stride,\n",
    "            max_pose_detections=2,\n",
    "            min_pose_score=0.5)\n",
    "\n",
    "        keypoint_coords *= output_scale\n",
    "\n",
    "        # TODO this isn't particularly fast, use GL for drawing and display someday...\n",
    "        overlay_image, body_part_coordinates = posenet.draw_skel_and_kp(\n",
    "            display_image, pose_scores, keypoint_scores, keypoint_coords, pa_status, calibrated, squat_count,\n",
    "            min_pose_score=0.15, min_part_score=0.1)\n",
    "\n",
    "        return overlay_image, body_part_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-heather",
   "metadata": {},
   "source": [
    "## Pose Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseAnalysis:\n",
    "    def __init__(self):\n",
    "        self.squat_measurement_needs = [\"leftShoulder\", \"rightShoulder\", \"leftHip\", \"rightHip\", \"leftKnee\", \"rightKnee\", \"leftAnkle\", \"rightAnkle\"]\n",
    "        self.status = \"Attempting Calibration\"\n",
    "        self.calibrated = 0\n",
    "        self.last_calibrated = time.time()\n",
    "        self.squat_counter = 0\n",
    "        self.cal_shoulder_hip = None\n",
    "        self.cal_hip_knee = None\n",
    "        self.cal_knee_ankle = None\n",
    "        self.cal_hip_ankle = None\n",
    "        self.minimum_squat_distance = None\n",
    "        self.user_up = True\n",
    "        \n",
    "        \n",
    "    def calculate_mean_height(self, measurements, body_part):\n",
    "        both_sides = [measurements[\"left%s\" % body_part][\"coordinates\"][0], measurements[\"left%s\" % body_part][\"coordinates\"][0]]\n",
    "        return statistics.mean(both_sides)\n",
    "    \n",
    "    def get_body_ratios(self, measurements):    \n",
    "        shoulders = self.calculate_mean_height(measurements, \"Shoulder\")\n",
    "        hips = self.calculate_mean_height(measurements, \"Hip\")\n",
    "        knees = self.calculate_mean_height(measurements, \"Knee\")\n",
    "        ankles = self.calculate_mean_height(measurements, \"Ankle\")\n",
    "        \n",
    "        # cartesian coordinates start on top left not bottom left so subtraction of y axis has to be reversed\n",
    "        return (hips - shoulders), (knees- hips), (ankles - knees), (ankles-hips)\n",
    "        \n",
    "    def calibrate(self, measurements):\n",
    "        s_h, h_k, k_a, h_a = self.get_body_ratios(measurements)\n",
    "        \n",
    "        # Reset Calibration if there has been too much time spent moving about \n",
    "        if time.time() - self.last_calibrated > 8:\n",
    "            print(time.time() - self.last_calibrated)\n",
    "            self.calibrated == 0\n",
    "\n",
    "        self.last_calibrated = time.time()\n",
    "        \n",
    "        #Ignoring Invalid distances\n",
    "        if any([x < 0 for x in [s_h, h_k, k_a, h_a]]):\n",
    "            pass\n",
    "            \n",
    "        # First calibration\n",
    "        elif self.calibrated == 0:\n",
    "            self.cal_shoulder_hip = s_h\n",
    "            self.cal_hip_knee = h_k\n",
    "            self.cal_knee_ankle = k_a\n",
    "            self.cal_hip_ankle = h_a\n",
    "            self.calibrated += 1\n",
    "        \n",
    "        # Subsequent Calibration\n",
    "        elif self.calibrated > 0 and self.calibrated < 3:\n",
    "            self.cal_shoulder_hip = statistics.mean([self.cal_shoulder_hip, s_h])\n",
    "            self.cal_hip_knee = statistics.mean([self.cal_hip_knee, h_k])\n",
    "            self.cal_knee_ankle = statistics.mean([self.cal_knee_ankle, k_a])\n",
    "            self.cal_hip_ankle = statistics.mean([self.cal_hip_ankle, h_a])\n",
    "            self.calibrated += 1\n",
    "            \n",
    "        # Last Calibration run\n",
    "        else:\n",
    "            self.calibrated += 1\n",
    "            self.minimum_squat_distance = math.sqrt(math.pow(self.cal_hip_knee, 2) + math.pow(self.cal_knee_ankle, 2))\n",
    "            print(\"Successfully calibrated\")\n",
    "            return True, \"Calibration Complete\"\n",
    "        \n",
    "        return True, \"Calibration # %d\" % self.calibrated\n",
    "    \n",
    "    \n",
    "    def assess_squat(self, measurements):\n",
    "        # Don't assess if the camera can't see all of the joints needed\n",
    "        if any([measurements[x][\"visible\"] == False for x in self.squat_measurement_needs]):\n",
    "            self.status = \"Step Back for full visibility\"\n",
    "            return False, \"Not all body parts visible\"\n",
    "        \n",
    "        # Not finished Calibrating\n",
    "        elif self.calibrated <= 3:\n",
    "            self.status = \"Calibrating # %d\" % self.calibrated\n",
    "            return True, self.calibrate(measurements)\n",
    "        \n",
    "        elif self.minimum_squat_distance is not None:\n",
    "            s_h, h_k, k_a, h_a = self.get_body_ratios(measurements)\n",
    "            \n",
    "            # Invalid measurement\n",
    "            if h_a < 0:\n",
    "                self.status = \"Invalid Measurement\"\n",
    "                return False, self.status\n",
    "            \n",
    "            # If shoulders are dipped\n",
    "            if s_h < (self.cal_shoulder_hip * 0.7):\n",
    "                self.status = \"Don't bend at the waist!!\"\n",
    "                return True, self.status\n",
    "                \n",
    "            # If the user is now in up Position\n",
    "            if h_a > self.minimum_squat_distance:\n",
    "                self.status = \"Assessing new Squat\"\n",
    "                self.user_up = True\n",
    "                return True, self.status\n",
    "            \n",
    "            # User is below minimum Squat position\n",
    "            elif h_a <= self.minimum_squat_distance and self.user_up is True:\n",
    "                self.squat_counter += 1\n",
    "                self.status = \"Successful Squat\"\n",
    "                self.user_up = False\n",
    "                return True, self.status\n",
    "            \n",
    "            # User is below up threshold but not low enough\n",
    "            else:\n",
    "                self.status = \"Squat not counted (up = %s)\" % str(self.user_up)\n",
    "                return False, self.status\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-synthesis",
   "metadata": {},
   "source": [
    "## Webcam Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-charles",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = IPython.display.display(\"\", display_id=1)\n",
    "d2 = IPython.display.display(\"\", display_id=2)\n",
    "\n",
    "print(\"starting webcam...\")\n",
    "cam = cv2.VideoCapture(1)\n",
    "counter = 0\n",
    "pa = PoseAnalysis()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model_cfg, model_outputs = posenet.load_model(101, sess)\n",
    "    output_stride = model_cfg['output_stride']\n",
    "    \n",
    "    while True:\n",
    "        t1 = time.time()\n",
    "        frame, body_part_coordinates= process_frame2(cam, pa.status, pa.calibrated >= 3, pa.squat_counter)\n",
    "        if counter > 50:\n",
    "            if pa.calibrated < 3 and counter % 20 == 0:\n",
    "                success, message = pa.assess_squat(body_part_coordinates)\n",
    "            elif counter % 3 == 0:\n",
    "                success, message = pa.assess_squat(body_part_coordinates)\n",
    "\n",
    "\n",
    "        # For Jupyter\n",
    "        im = array_to_image(frame)\n",
    "        d.update(im)\n",
    "        # For Normal Python\n",
    "        # cv2.imshow(\"preview\", frame)\n",
    "\n",
    "\n",
    "        t2 = time.time()\n",
    "        s = f\"\"\"{int(1/(t2-t1))} FPS\"\"\"\n",
    "        if pa.calibrated < 3:\n",
    "            message = \"<h1 style='font-size: 45;'>Calibrating</h1>\"\n",
    "        else:\n",
    "            message = \"<h1 style='font-size: 45;'>%s</h1>\" % \"Squat Count = %d\" % pa.squat_counter\n",
    "#         d2.update( IPython.display.HTML(message) )\n",
    "        counter += 1\n",
    "        \n",
    "        key = cv2.waitKey(20)\n",
    "        if key == 27:  # exit on ESC\n",
    "            break\n",
    "\n",
    "cv2.destroyWindow(\"preview\")\n",
    "vc.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-humanity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    "\t'nose': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftEye': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightEye': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftEar': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightEar': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftShoulder': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightShoulder': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftElbow': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightElbow': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftWrist': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightWrist': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftHip': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightHip': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftKnee': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightKnee': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'leftAnkle': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t},\n",
    "\t'rightAnkle': {\n",
    "\t\t'coordinates': array([0., 0.]),\n",
    "\t\t'visible': False\n",
    "\t}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-replacement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
